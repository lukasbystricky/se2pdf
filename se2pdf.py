import sys
import pdb
import logging
import re
import os
import urllib.request
import cssutils
import argparse
from weasyprint import HTML, CSS
from bs4 import BeautifulSoup

skip_toc = False          # do not include the the table of contents 
cleanup = False           # remove intermediary files generated by se2pdf
book_name = sys.argv[1]

base_directory = "https://raw.githubusercontent.com/standardebooks/" + book_name + "/master/"
cssutils.log.setLevel(logging.CRITICAL)

def write_pdf():
    if os.path.isfile(book_name + ".log"):
        os.remove(book_name + ".log")

    logger = logging.getLogger('weasyprint')
    logger.addHandler(logging.FileHandler('./' + book_name + '.log'))

    html=HTML(book_name + ".xhtml", encoding="utf8")
    html.write_pdf(book_name + ".pdf", stylesheets=[book_name + ".css"])

    if cleanup:
        os.remove(book_name + ".xhtml")
        os.remove(book_name + ".css")
        os.remove(book_name + ".log")

def generate_css():
    css = cssutils.parseFile("css/book.css")
    css_custom = cssutils.parseFile("css/custom.css")
    css_files = ["se.css", "core.css", "local.css"]

    for rule in css_custom:
            if rule.type == 1: # only insert regular style rules
                css.insertRule(rule)

    for i in range(0, len(css_files)):
        stylesheet = urllib.request.urlopen(base_directory + "src/epub/css/" + css_files[i])
        css_tmp = stylesheet.read().decode("utf-8") 

        css_file = cssutils.parseString(css_tmp)
        
        for rule in css_file:
            if rule.type == 1: # only insert regular style rules
                css.insertRule(rule)

    css_str = css.cssText.decode("utf-8")
    css_str = re.sub("\"se:", "\"", css_str)                           # remove se: specifier
    css_str = re.sub("z3998:", "", css_str)                            # remove z3998: specifier
    css_str = re.sub("\\[(?:\\|type~=\")(.+?)\"\\]", ".\\1", css_str)  # replace epub|type with class
    css_str = re.sub("xml\\|", "", css_str)                            # remove xml namespace specifier

    # override styling from core.css
    css_str = css_str + "\na.noteref { vertical-align: top }"

    f=open(book_name + ".css","w")
    f.write(css_str)
    f.close()

def generate_html():

    content = urllib.request.urlopen(base_directory + "src/epub/content.opf")

    xmlsoup = BeautifulSoup(content.read().decode("utf-8"), 'xml')
    files=xmlsoup.find_all("itemref")

    html_str = "<section class=\"fullpage\"> <img src=\"" + base_directory + "/src/epub/images/cover.svg\"></img></section>"
    
    exclude_from_toc = ["#titlepage", "#imprint", "#colophon", "#uncopyright"]
    frontmatter_sections = get_frontmatter(files)

    tocAdded = False

    for x in files:
        temp=x.get("idref")
        temp1=temp.split(".")[0]
        body = get_body(base_directory + "src/epub/text/" + temp1 + ".xhtml")

        html_tmp = ""

        if body.section is not None:

            if ("halftitlepage" in body.section.get("epub:type")):
                body.section["epub:type"] = body.section.get("epub:type", "") + " " + "bodymatter"
            else:
                body.section["epub:type"] = body.section.get("epub:type", "") + " " + body.get("epub:type")

            if ("dedication" in body.section.get("epub:type")) \
                    or ("epigraph" in body.section.get("epub:type")):
                exclude_from_toc.append("#" + body.section.get("id"))

            if "frontmatter" not in body.section.get("epub:type") and "halftitlepage" not in body.section.get("epub:type") \
                and not skip_toc and not tocAdded:
                    html_tmp += create_toc(exclude_from_toc, frontmatter_sections)
                    tocAdded = True

            add_page_references(body.section, frontmatter_sections)

            html_tmp += str(re.sub("(?:, )?\\[?\\'\\\\n\\'(?:, )?\\]?", "", str(body.contents)))
            html_tmp = html_tmp.replace("z3998:", "",)
            html_tmp = html_tmp.replace("epub:type", "class")
            html_tmp = html_tmp.replace("xml:lang", "lang")
            html_tmp = html_tmp.replace("<article class=\"", "<article class=\"bodymatter ")

            html_str += html_tmp
    
    html_str +=  "<section id=\"backcover\"><div>" + xmlsoup.find("meta", {"id":"long-description"}).text + "</div></section>"

    f=open(book_name + ".xhtml","w")
    f.write(html_str)
    f.close()

def create_toc(exclude_ids, frontmatter_ids):
    toc = urllib.request.urlopen(base_directory + "src/epub/toc.xhtml")
    toc_str = toc.read().decode("utf-8")
    soup = BeautifulSoup(toc_str, 'html.parser')
    section = soup.nav
    section["epub:type"] = section.get("epub:type", "") + " " + "bodymatter"
    section["id"] = "contents"

    for a_tag in soup.find_all('a'):
        href = a_tag["href"]
        href = href.replace("text/", "#")
        href = href.replace(".xhtml", "")
        href = re.sub("[\\S]+#", "#", href)
        a_tag["href"] = href

        if a_tag.get("href", "") in exclude_ids:
            a_tag.decompose()
            continue

        if a_tag.get("href", "") != "#halftitlepage" and a_tag.get("href", "") in frontmatter_ids:
            a_tag["class"] = a_tag.get("class", []) + ["frontmatter"]

    soup_str = str(section)
    soup_str = re.sub("<li>[\\s]+?</li>", "", soup_str)
    soup_str = re.sub("(<a .*?>)[\\s\n]*?(.*?)[\\s\n]*?</a>", "\\2\\1</a>", soup_str)
    soup_str = re.sub("<li>([\\s\\S]+?)<a", "<li><span>\\1</span><a", soup_str)
    soup_str = re.sub("<nav ", "<section ", soup_str)
    soup_str = re.sub("</nav>", "</section>", soup_str)
    return soup_str

def get_body(file):
    html = urllib.request.urlopen(file)
    html_str = html.read().decode("utf-8")
    soup = BeautifulSoup(html_str, 'html.parser')

    correct_hrefs(soup)

    return soup.body

def get_frontmatter(files):
    frontmatter = ["#titlepage", "#imprint"]
    all_files = []

    for f in files:
        all_files.append("#" + f["idref"].replace(".xhtml",""))

    if "#halftitlepage" in all_files:
        for f in all_files:
            if f == "#halftitlepage":
                break
            
            if f not in frontmatter:
                frontmatter.append(f)

    return frontmatter

def correct_hrefs(soup):
    for a_tag in soup.find_all('a'):
        href = a_tag["href"]
        href = href.replace(".xhtml", "") #remove trailing .xhtml
        if "colophon" not in soup.body.section["epub:type"] and "imprint" not in soup.body.section["epub:type"]:
            href = re.sub("[\\S]+#", "#", href) #remove extra # in id references, proper urls in colophon and imprint can extra #
        else:
            href = href.replace("uncopyright", "#uncopyright")

        a_tag["href"] = href
        
    for img_tag in soup.find_all('img'):
        src =  img_tag["src"]
        src = src.replace("../", base_directory + "src/epub/")
        img_tag["src"] = src

def add_page_references(soup, frontmatter_sections):
    page_ref_contents = ["here", "Here", "above", "Above", "below", "Below", "supra", "Supra", "infra", "Infra"]
    for a_tag in soup.find_all('a'):
        href = a_tag["href"]
        if "-p-" in href:
            if re.sub("<.*?>(.*?)</.*?>","\\1", str(a_tag.contents[0])) in page_ref_contents:
                a_tag.contents = ""
                if re.search("(#.*)(?:-p-)", str(a_tag)).group(1) in frontmatter_sections:
                    a_tag["class"] = a_tag.get("class", []) + ["fontpagereference"]
                else:
                    a_tag["class"] = a_tag.get("class", []) + ["pagereference"]

generate_css()
generate_html()
write_pdf()