import sys
import pdb
import logging
import re
import os
import urllib.request
import cssutils
import argparse
from weasyprint import HTML, CSS
from bs4 import BeautifulSoup

skip_toc = False          # do not include the the table of contents 
cleanup = False           # remove intermediary files generated by se2pdf
book_name = sys.argv[1]

base_directory = "https://raw.githubusercontent.com/standardebooks/" + book_name + "/master/"
cssutils.log.setLevel(logging.CRITICAL)

def write_pdf():
    if os.path.isfile(book_name + ".log"):
        os.remove(book_name + ".log")

    logger = logging.getLogger('weasyprint')
    logger.addHandler(logging.FileHandler('./' + book_name + '.log'))

    html=HTML(book_name + ".xhtml", encoding="utf8")
    html.write_pdf(book_name + ".pdf", stylesheets=[book_name + ".css"])

    if cleanup:
        os.remove(book_name + ".xhtml")
        os.remove(book_name + ".css")
        os.remove(book_name + ".log")

def generate_css():
    css = cssutils.parseFile("book.css")
    
    css_files = ["se.css", "core.css", "local.css"]

    for i in range(0, len(css_files)):
        stylesheet = urllib.request.urlopen(base_directory + "src/epub/css/" + css_files[i])
        css_tmp = stylesheet.read().decode("utf-8") 

        css_file = cssutils.parseString(css_tmp)
        
        for rule in css_file:
            if rule.type == 1: # only insert regular style rules
                css.insertRule(rule)

    css_str = css.cssText.decode("utf-8")
    css_str = re.sub("\"se:", "\"", css_str)                           # remove se: specifier
    css_str = re.sub("z3998:", "", css_str)                            # remove z3998: specifier
    css_str = re.sub("\\[(?:\\|type~=\")(.+?)\"\\]", ".\\1", css_str)  # replace epub|type with class
    css_str = re.sub("xml\\|", "", css_str)                            # remove xml namespace specifier

    # override styling from core.css
    css_str = css_str + "\na.noteref { font-size: 0.6em; vertical-align: top }"

    f=open(book_name + ".css","w")
    f.write(css_str)
    f.close()

def generate_html():

    content = urllib.request.urlopen(base_directory + "src/epub/content.opf")

    xmlsoup = BeautifulSoup(content.read().decode("utf-8"), 'xml')
    files=xmlsoup.find_all("itemref")

    html_str = "<section class=\"fullpage\"> <img src=\"" + base_directory + "/src/epub/images/cover.svg\"></img></section>"
    
    exclude_from_toc = ["#titlepage", "#imprint", "#colophon", "#uncopyright"]
    frontmatter_sections = []
    tocAdded = False

    for x in files:
        temp=x.get("idref")
        temp1=temp.split(".")[0]
        body = get_body(base_directory + "src/epub/text/" + temp1 + ".xhtml")

        html_tmp = ""

        if body.section is not None:
            body.section["epub:type"] = body.section.get("epub:type", "") + " " + body.get("epub:type")

        if "frontmatter" in body.get("epub:type"):
            frontmatter_sections.append("#" + body.section.get("id"))
            if ("dedication" in body.section.get("epub:type")) \
                 or ("epigraph" in body.section.get("epub:type")):
                exclude_from_toc.append("#" + body.section.get("id"))
            
        elif not skip_toc and not tocAdded:
                html_tmp += create_toc(exclude_from_toc, frontmatter_sections)
                tocAdded = True

        html_tmp += str(re.sub("(?:, )?\\[?\\'\\\\n\\'(?:, )?\\]?", "", str(body.contents)))
        html_tmp = html_tmp.replace("z3998:", "",)
        html_tmp = html_tmp.replace("epub:type", "class")
        html_tmp = html_tmp.replace("xml:lang", "lang")
        html_tmp = html_tmp.replace("<article class=\"", "<article class=\"bodymatter ")

        html_str += html_tmp
    
    html_str +=  "<section id=\"backcover\"><div>" + xmlsoup.find("meta", {"id":"long-description"}).text + "</div></section>"

    f=open(book_name + ".xhtml","w")
    f.write(html_str)
    f.close()

def create_toc(exclude_ids, frontmatter_ids):
    toc = urllib.request.urlopen(base_directory + "src/epub/toc.xhtml")
    toc_str = toc.read().decode("utf-8")
    soup = BeautifulSoup(toc_str, 'html.parser')
    section = soup.nav

    for a_tag in soup.find_all('a'):
        href = a_tag["href"]
        href = href.replace("text/", "#")
        href = href.replace(".xhtml", "")
        href = re.sub("[\\S]+#", "#", href)
        a_tag["href"] = href

        if a_tag.get("href", "") in exclude_ids:
            a_tag.decompose()
            continue

        if a_tag.get("href", "") in frontmatter_ids:
            a_tag["class"] = a_tag.get("class", []) + ["frontmatter"]

    soup_str = str(section)
    soup_str = re.sub("<li>[\\s]+?</li>", "", soup_str)
    soup_str = re.sub("(<a .*?>)[\\s\n]*?(.*?)[\\s\n]*?</a>", "\\2\\1</a>", soup_str)
    soup_str = re.sub("<li>([\\s\\S]+?)<a", "<li><span>\\1</span><a", soup_str)
    soup_str = re.sub("<nav epub:type=\"toc\" id=\"toc\">", "<section id=\"contents\">", soup_str)
    soup_str = re.sub("</nav>", "</section>", soup_str)
    return soup_str

def get_body(file):
    html = urllib.request.urlopen(file)
    html_str = html.read().decode("utf-8")
    soup = BeautifulSoup(html_str, 'html.parser')

    correct_hrefs(soup)

    return soup.body

def correct_hrefs(soup):
    for a_tag in soup.find_all('a'):
        href = a_tag["href"]
        href = href.replace(".xhtml", "") #remove trailing .xhtml
        if "colophon" not in soup.body.section["epub:type"] and "imprint" not in soup.body.section["epub:type"]:
            href = re.sub("[\\S]+#", "#", href) #remove extra # in id references, proper urls in colophon and imprint can extra #

        a_tag["href"] = href
        
    for img_tag in soup.find_all('img'):
        src =  img_tag["src"]
        src = src.replace("../", base_directory + "src/epub/")
        img_tag["src"] = src

generate_css()
generate_html()
write_pdf()